{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "q_b_ifobbjU7",
      "metadata": {
        "id": "q_b_ifobbjU7"
      },
      "source": [
        "#Code for ViViT model [[paper]](https://arxiv.org/abs/2103.15691)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "rkt-0enhb0qG",
      "metadata": {
        "id": "rkt-0enhb0qG"
      },
      "source": [
        "## Imports and Global declarations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "angry-effectiveness",
      "metadata": {
        "id": "angry-effectiveness"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torchvision as tv\n",
        "from torch.utils.data import random_split, DataLoader,Dataset\n",
        "\n",
        "import os\n",
        "import time\n",
        "import random\n",
        "import math\n",
        "\n",
        "# !pip install einops icecream\n",
        "import decord\n",
        "import numpy as np\n",
        "import gc\n",
        "from einops import rearrange, repeat,reduce\n",
        "from einops.layers.torch import Rearrange\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "from icecream import ic\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8ifOyxNa5Cnp",
      "metadata": {
        "id": "8ifOyxNa5Cnp"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda:0'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# set device\n",
        "device ='cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "C9gk3l2-rSt1",
      "metadata": {
        "id": "C9gk3l2-rSt1"
      },
      "outputs": [],
      "source": [
        "# Instantiate tensorboard writer\n",
        "#tb_writer = SummaryWriter()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "yDjl36ascCbH",
      "metadata": {
        "id": "yDjl36ascCbH"
      },
      "source": [
        "## DataLoader for UCF101 dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "rational-neutral",
      "metadata": {
        "id": "rational-neutral"
      },
      "outputs": [],
      "source": [
        "# dataset params\n",
        "frames_per_clip = 8\n",
        "dataset_dir=\"./ucf/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist\"\n",
        "video_dir = \"./ucf/UCF101/UCF-101\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "documentary-python",
      "metadata": {
        "id": "documentary-python"
      },
      "outputs": [],
      "source": [
        "# Dataset Class\n",
        "class UCFDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"\n",
        "    Dataset Class for reading UCF101 dataset  \n",
        "    \n",
        "    Args:\n",
        "        dataset_dir: (str) - root directory of dataset\n",
        "        subset: (str) - train or test subset\n",
        "        video_list_file: (str) - file name containing list of video names \n",
        "        frames_per_clip: (int) - number of frames to be read in every video clip [default:16]\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset_dir, subset, video_list_file, frames_per_clip=16):\n",
        "        super().__init__()\n",
        "        self.dataset_dir = dataset_dir\n",
        "        self.video_dir = video_dir\n",
        "        self.subset=subset\n",
        "        self.video_list_file = video_list_file\n",
        "        self.video_list = []\n",
        "        self.labels = []\n",
        "        self.indices = []\n",
        "\n",
        "        for i in [1,2,3]:\n",
        "            with open(f'{dataset_dir}/{video_list_file}{str(i)}.txt') as video_names_file:\n",
        "                if self.subset==\"train\":\n",
        "                    tempvideo_list,templabels = zip(*(files[:-1].split() for files in video_names_file.readlines()))\n",
        "                    self.video_list += tempvideo_list\n",
        "                    self.labels += templabels\n",
        "                else:\n",
        "                    tempvideo_list = [files[:-1] for files in video_names_file.readlines()]\n",
        "                    templabels = [None]\n",
        "                    self.video_list += tempvideo_list\n",
        "                    self.labels += templabels\n",
        "                    # with open(f'{dataset_dir}/classInd.txt') as classIndices:\n",
        "                    #     values,keys=zip(*(files[:-1].split() for files in classIndices.readlines()))\n",
        "                    #     tempindices = dict( (k,v) for k,v in zip(keys,values))\n",
        "                    \n",
        "            \n",
        "            #self.indices.append(tempindices)\n",
        "        \n",
        "\n",
        "        self.frames_per_clip = frames_per_clip\n",
        "\n",
        "        self.transform = tv.transforms.Compose([\n",
        "          #tv.transforms.GaussianBlur(9, sigma=(0.1, 2.0)),\n",
        "          tv.transforms.Resize(256,interpolation=tv.transforms.InterpolationMode.BICUBIC),\n",
        "          tv.transforms.CenterCrop(224),\n",
        "          tv.transforms.ToTensor(),\n",
        "          tv.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "        ])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.video_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        videoname = f'{self.video_list[idx]}'\n",
        "        vid = decord.VideoReader(f'{self.video_dir}/{videoname}', ctx=decord.cpu(0))\n",
        "        nframes = len(vid)\n",
        "\n",
        "        # if number of frames of video is less than frames_per_clip, repeat the frames\n",
        "        if nframes <= self.frames_per_clip:\n",
        "            idxs = np.arange(0, self.frames_per_clip).astype(np.int32)\n",
        "            idxs[nframes:] %= nframes\n",
        "\n",
        "        # else if frames_per_clip is greater, sample uniformly seperated frames\n",
        "        else:\n",
        "            idxs = np.linspace(0, nframes-1, self.frames_per_clip)\n",
        "            idxs = np.round(idxs).astype(np.int32)\n",
        "\n",
        "        imgs = []\n",
        "        for k in idxs:\n",
        "            frame = Image.fromarray(vid[k].asnumpy())\n",
        "            frame = self.transform(frame)\n",
        "            imgs.append(frame)\n",
        "        imgs = torch.stack(imgs)\n",
        "\n",
        "        # if its train subset, return both the frames and the label \n",
        "        if self.subset==\"train\":\n",
        "            label = int(self.labels[idx]) - 1    \n",
        "        # else, for test subset, read the label index\n",
        "        else:\n",
        "            classttl = {}\n",
        "            with open(f'{dataset_dir}/classInd.txt') as clsidx:\n",
        "                \n",
        "                classttl = {v:int(k) for k, v in (l.split() for l in clsidx)}\n",
        "\n",
        "            clsname = videoname.split('/')[0]\n",
        "            label= classttl[clsname] -1\n",
        "        return imgs,label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6zXGDy7QCpHy",
      "metadata": {
        "id": "6zXGDy7QCpHy"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train samples: 24434\n",
            "Validation samples: 4313\n",
            "Test samples: 11213\n"
          ]
        }
      ],
      "source": [
        "#Instantiate and create train-val-test split\n",
        "\n",
        "train_val_data = UCFDataset( dataset_dir = dataset_dir, subset=\"train\", video_list_file=\"trainlist0\",frames_per_clip=frames_per_clip)\n",
        "\n",
        "train_len=int(0.85*len(train_val_data))\n",
        "train_val_split = [ train_len, len(train_val_data) - train_len ] \n",
        "\n",
        "train_data , val_data = random_split(train_val_data,train_val_split)\n",
        "test_data = UCFDataset( dataset_dir = dataset_dir, subset=\"test\", video_list_file=\"testlist0\" ,frames_per_clip=frames_per_clip)\n",
        "\n",
        "print(f\"Train samples: {len(train_data)}\")\n",
        "print(f\"Validation samples: {len(val_data)}\")\n",
        "print(f\"Test samples: {len(test_data)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "rotary-ladder",
      "metadata": {
        "id": "rotary-ladder",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8, 3, 224, 224])\n",
            "94\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#example frame from a random video to check if dataloader's working properly\n",
        "plt.imshow(((test_data[35][0][0].permute(1,2,0)*255).int()).numpy())\n",
        "print(train_data[35][0].shape)  #Size([8, 3, 224, 224])\n",
        "print(train_data[35][1])        # label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "adapted-aviation",
      "metadata": {
        "id": "adapted-aviation"
      },
      "outputs": [],
      "source": [
        "# data loading params\n",
        "batch_size = 64\n",
        "test_batch_size = 1\n",
        "num_workers = 8\n",
        "pin_memory = True\n",
        "num_classes=101"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "accepting-payment",
      "metadata": {
        "id": "accepting-payment"
      },
      "outputs": [],
      "source": [
        "# Dataloaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=test_batch_size)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "YqviNYNCLiW4",
      "metadata": {
        "id": "YqviNYNCLiW4"
      },
      "source": [
        "## Model definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "comparable-crack",
      "metadata": {
        "id": "comparable-crack"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    \"\"\"\n",
        "    Builds a simple feed forward network\n",
        "    \n",
        "    Args:\n",
        "        dim: (int) - inner dimension of| embeddings \n",
        "        inner_dim: (int) - dimension of transformer head  \n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dim, inner_dim,n_class,encoder):     #dim would be the output image feature from dinov2\n",
        "                                                        \n",
        "        super().__init__()\n",
        "        # mlp with GELU activation function\n",
        "        self.encoder = encoder\n",
        "        self.mlp = nn.Sequential(\n",
        "            #nn.Linear(dim, inner_dim),\n",
        "            #nn.GELU(),\n",
        "            #nn.Dropout(0.5),\n",
        "            #nn.Linear(inner_dim, inner_dim),\n",
        "            #nn.GELU(),\n",
        "            nn.Linear(dim, n_class),\n",
        "            #nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is [256,8,3,224,224]\n",
        "        \n",
        "        #print('x shape is',x.shape)\n",
        "        # avg = []\n",
        "        \n",
        "        # for i in range(8):\n",
        "        #     xi = x[:,i,:]\n",
        "            \n",
        "        #     #encode x to [8,384]\n",
        "        #     e = []\n",
        "        #     with torch.no_grad():\n",
        "        #         # features_dict = self.encoder.forward_features(xi)\n",
        "        #         # e = features_dict['x_norm_patchtokens']\n",
        "        #         e = self.encoder(xi).reshape(x.shape[0],1,384)\n",
        "        #     print('e shape ',e.shape)   #256,1,384\n",
        "        #     avg.append(e)\n",
        "        # avg = torch.cat(avg,dim=1)    \n",
        "        \n",
        "               \n",
        "        #avg = reduce(avg, \"f t c -> f c\",'mean')        #[16,384]   (b, l)\n",
        "\n",
        "        with torch.no_grad():    \n",
        "            B,T,C,H,W = x.shape\n",
        "            x = x.reshape(B*T,C,H,W) # b c t h w -> b t c h w -> b*t c h w\n",
        "            #print('x shape is',x.shape)\n",
        "            output = self.encoder(x)\n",
        "            output = output.reshape(B,T,-1) # b*t d -> b t d\n",
        "            avg = output.mean(dim=-2) # b t d -> b d\n",
        "        #output = linear_classifier(output) # b d -> b l\n",
        "        #print(avg.shape)\n",
        "        \n",
        "        return self.mlp(avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "economic-limitation",
      "metadata": {
        "id": "economic-limitation"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /home/z3qian/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLP(\n",
              "  (encoder): DinoVisionTransformer(\n",
              "    (patch_embed): PatchEmbed(\n",
              "      (proj): Conv2d(3, 384, kernel_size=(14, 14), stride=(14, 14))\n",
              "      (norm): Identity()\n",
              "    )\n",
              "    (blocks): ModuleList(\n",
              "      (0-11): 12 x NestedTensorBlock(\n",
              "        (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        (attn): MemEffAttention(\n",
              "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
              "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
              "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
              "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls1): LayerScale()\n",
              "        (drop_path1): Identity()\n",
              "        (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "        (mlp): Mlp(\n",
              "          (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
              "          (act): GELU(approximate='none')\n",
              "          (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
              "          (drop): Dropout(p=0.0, inplace=False)\n",
              "        )\n",
              "        (ls2): LayerScale()\n",
              "        (drop_path2): Identity()\n",
              "      )\n",
              "    )\n",
              "    (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
              "    (head): Identity()\n",
              "  )\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=384, out_features=101, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# instantiate model and plot on tensorboard\n",
        "#model = ViViT(image_size=224, patch_size=16, num_classes=num_classes, frames_per_clip=frames_per_clip)\n",
        "dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14',force_reload=True)\n",
        "dinov2_vits14.to(device)\n",
        "for param in dinov2_vits14.parameters():\n",
        "    param.requires_grad= False\n",
        "model = MLP(384,512,101,dinov2_vits14)\n",
        "#frames, _ = next(iter(train_loader))\n",
        "#tb_writer.add_graph(model, frames)\n",
        "model.to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "HiyjllqxL9bV",
      "metadata": {
        "id": "HiyjllqxL9bV"
      },
      "source": [
        "## Training utils "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "rY9aVH4pZM4D",
      "metadata": {
        "id": "rY9aVH4pZM4D"
      },
      "outputs": [],
      "source": [
        "# training hyper-params\n",
        "lr=0.1\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "v3JiODtrd0j-",
      "metadata": {
        "id": "v3JiODtrd0j-"
      },
      "outputs": [],
      "source": [
        "# define the loss and optimizers\n",
        "loss_criterion = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), momentum=0.9, weight_decay=0,lr=lr)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, 1_000_00, eta_min=0)\n",
        "#optimizer = torch.optim.Adam(model.parameters(),lr)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=lr,momentum=0.9,weight_decay=0.01)\n",
        "#scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.95)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "least-visitor",
      "metadata": {
        "id": "least-visitor"
      },
      "outputs": [],
      "source": [
        "# training step for every epoch\n",
        "def train_step(loader,epoch,):\n",
        "    \n",
        "    model.train()\n",
        "    # model.encoder.eval()\n",
        "    total_epoch_loss=0\n",
        "    \n",
        "    for batch_id, (video_data,labels) in enumerate(loader):\n",
        "\n",
        "        # video_data,labels = video_data.to(device), labels.to(device)\n",
        "        video_data,labels = video_data.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        prediction = model(video_data)\n",
        "\n",
        "        loss = loss_criterion(prediction,labels)\n",
        "        total_epoch_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        corrects = (torch.argmax(prediction,dim=1)==labels).sum()\n",
        "        bacc = corrects/batch_size\n",
        "        del video_data\n",
        "        del labels\n",
        "\n",
        "        gc.collect()\n",
        "        \n",
        "        #tb_writer.add_scalar(\"Train/Loss\",loss.item(),((len(loader))*(epoch-1))+batch_id)\n",
        "        \n",
        "        \n",
        "        print(f\"\\n[Train Epoch]: {epoch} Train Loss: {loss.item()}, Batch Acc is {bacc.item()}\")\n",
        "\n",
        "    return total_epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "elegant-tulsa",
      "metadata": {
        "id": "elegant-tulsa"
      },
      "outputs": [],
      "source": [
        "# validation step for every epoch\n",
        "def val_step(loader,epoch=None):\n",
        "\n",
        "    model.eval()\n",
        "    total_loss=0\n",
        "    corrects=0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch_id, (video_data,labels) in enumerate(loader):\n",
        "\n",
        "            video_data,labels = (video_data).to(device), labels.to(device)\n",
        "\n",
        "            prediction = model(video_data)\n",
        "            \n",
        "            loss = loss_criterion(prediction,labels)\n",
        "            total_loss += loss.item()\n",
        "            corrects+= (torch.argmax(prediction,dim=1)==labels).sum()\n",
        "    \n",
        "    accuracy = corrects/(len(loader)*batch_size)\n",
        "    \n",
        "    print(f\"\\n[Val Epoch]: {epoch} , Accuracy: {accuracy}, Valid Loss: {loss.item()}\")\n",
        "    #tb_writer.add_scalar(\"Validation/Loss\",loss.item(),epoch)\n",
        "    #tb_writer.add_scalar(\"Validation/Accuracy\",accuracy,epoch)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "MHl6bllSMGJX",
      "metadata": {
        "id": "MHl6bllSMGJX"
      },
      "source": [
        "## Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "df7fe42b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mlp.0.weight\n",
            "mlp.0.bias\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if param.requires_grad:\n",
        "        print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "worst-bedroom",
      "metadata": {
        "id": "worst-bedroom",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee56bc10f796403da4a0067095476cac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Train Epoch]: 1 Train Loss: 5.326816558837891, Batch Acc is 0.015625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 4.8318305015563965, Batch Acc is 0.046875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.602318286895752, Batch Acc is 0.28125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.0715742111206055, Batch Acc is 0.390625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.3045413494110107, Batch Acc is 0.40625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.8794362545013428, Batch Acc is 0.46875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.3950183391571045, Batch Acc is 0.46875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.476335287094116, Batch Acc is 0.546875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.5010993480682373, Batch Acc is 0.484375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.283100128173828, Batch Acc is 0.625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4331538677215576, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.482462167739868, Batch Acc is 0.59375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.589104175567627, Batch Acc is 0.609375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2699445486068726, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.9438729286193848, Batch Acc is 0.671875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6536805629730225, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9985450506210327, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6940629482269287, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.8126187324523926, Batch Acc is 0.6875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.2428274154663086, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.481971025466919, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3315067291259766, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.708655595779419, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.2627224922180176, Batch Acc is 0.65625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1464816331863403, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.5675909519195557, Batch Acc is 0.671875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.2487480640411377, Batch Acc is 0.65625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.48749577999115, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6847831010818481, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.078192114830017, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5147475004196167, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2575006484985352, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9918133020401, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9753148555755615, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.4522292613983154, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.558380365371704, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8133608102798462, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.3798983097076416, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.4070584774017334, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 3.0045220851898193, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.090995192527771, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8390446901321411, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5132359266281128, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7708220481872559, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8363072872161865, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9110190868377686, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5057460069656372, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6485087871551514, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6635568141937256, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0626367330551147, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.463793158531189, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.3426852226257324, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3623079061508179, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4774866104125977, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.901364803314209, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1375741958618164, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.1435391902923584, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7631929516792297, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.729798436164856, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6298490762710571, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.394815593957901, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.995480477809906, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7554315328598022, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8833239078521729, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.238342046737671, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4454901218414307, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2587355375289917, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5689263343811035, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0553354024887085, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.379772663116455, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8468406200408936, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3428020477294922, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6017727851867676, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.6071884632110596, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8942714929580688, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1338518857955933, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8210746049880981, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.02543044090271, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1715131998062134, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6622973680496216, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5515203475952148, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6110507249832153, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0127108097076416, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4090089797973633, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.8165371417999268, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.422304630279541, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2128212451934814, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.770716667175293, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7143223881721497, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.1514129638671875, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.137373447418213, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8579407930374146, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6898106336593628, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 4.4230427742004395, Batch Acc is 0.703125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7898902893066406, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8987241983413696, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.088750123977661, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.479885458946228, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.904229164123535, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7556875944137573, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5289591550827026, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.420807957649231, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2752280235290527, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.485150098800659, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8687289357185364, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2558479309082031, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1072369813919067, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6156703233718872, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.3983564376831055, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.186285376548767, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.595332145690918, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9462417364120483, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.31506603956222534, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.8282270431518555, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9832172989845276, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0568416118621826, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7623070478439331, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6383733153343201, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7722336053848267, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7715951204299927, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4045721292495728, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2412333488464355, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4063001871109009, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3133504390716553, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2960244417190552, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.494391679763794, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2445998191833496, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5252768993377686, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.5285391807556152, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9142052531242371, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8879257440567017, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9209410548210144, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5449855327606201, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.842720091342926, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5158909559249878, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5239520072937012, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.012429118156433, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.1547820568084717, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8630622625350952, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7971736192703247, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5900680422782898, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.026208519935608, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7863807082176208, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.150813341140747, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9230149984359741, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9195964336395264, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7625240087509155, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5413416028022766, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3067944049835205, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1035467386245728, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7548136711120605, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8613816499710083, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9226971864700317, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.545760452747345, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8448798656463623, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.9928380250930786, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.147302269935608, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.648964524269104, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8264732956886292, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1410962343215942, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.399043321609497, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3212097883224487, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7500740885734558, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9893842339515686, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4961512088775635, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.3568955063819885, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7161709070205688, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6442927122116089, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.45312762260437, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.588716745376587, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4787216782569885, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3249847888946533, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.12343168258667, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2701531648635864, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.335506796836853, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6726766228675842, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9547158479690552, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9791581630706787, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9942968487739563, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7020490169525146, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5902597308158875, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6257860064506531, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9001234173774719, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7004987597465515, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2140153646469116, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2432701587677002, Batch Acc is 0.703125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3371151685714722, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3799365758895874, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0535006523132324, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2633910179138184, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2835066318511963, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5351346731185913, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.273749589920044, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.062137484550476, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0247458219528198, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7574691772460938, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.3433166742324829, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5503263473510742, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9531581401824951, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6936597228050232, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.81773841381073, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4201664924621582, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3801723718643188, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9320226907730103, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.1287669688463211, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9220046997070312, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.178436517715454, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9513423442840576, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4728221595287323, Batch Acc is 0.96875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2032785415649414, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2525898218154907, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7757114768028259, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.576806902885437, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.694362759590149, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6642107963562012, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.273113965988159, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3412456512451172, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4099475145339966, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7032397985458374, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3388957977294922, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2157260179519653, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3149431943893433, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.40192449092865, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5048988461494446, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6876206398010254, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7384135127067566, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.2103381156921387, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4853254556655884, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3645838499069214, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6801238059997559, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1382358074188232, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8159006237983704, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9915085434913635, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.518498420715332, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9258153438568115, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8602662682533264, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.038806676864624, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0719395875930786, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8652437925338745, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5403622388839722, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2441318035125732, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7351434230804443, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.6024812459945679, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5634047389030457, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5041366219520569, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.576530396938324, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.75531405210495, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2957680225372314, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.078000545501709, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.828282117843628, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5655643343925476, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6183712482452393, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0794990062713623, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1581498384475708, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.46323949098587036, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0329347848892212, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8195648789405823, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.139714241027832, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.858232855796814, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4480891525745392, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.40120115876197815, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8171214461326599, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.01007878780365, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8113279938697815, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0063626766204834, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5865436792373657, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.649077832698822, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6175359487533569, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6518346071243286, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.1925545036792755, Batch Acc is 0.96875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9069033265113831, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5142667293548584, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.034280776977539, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.347737193107605, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4360302686691284, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6987481117248535, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4869873523712158, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0190469026565552, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9327242374420166, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9046351313591003, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6672022938728333, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5995424389839172, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.48589709401130676, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.013086199760437, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.5098775625228882, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7876785397529602, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1733477115631104, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0591639280319214, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5992801785469055, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6740979552268982, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9547480940818787, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7229198217391968, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3835172653198242, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.22894643247127533, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.1613491028547287, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2110272645950317, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8523122072219849, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4119735360145569, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.46355563402175903, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.2046748399734497, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3996386528015137, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.96775484085083, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.807274580001831, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.27752685546875, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.852554202079773, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.318145751953125, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.711344599723816, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6907079219818115, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.07112979888916, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.33949044346809387, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.49083295464515686, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.22237534821033478, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.101122260093689, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7565736174583435, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.42649078369140625, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.571296751499176, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.567869246006012, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5701040029525757, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.39738550782203674, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.730515480041504, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4395821988582611, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.1954022645950317, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6809728145599365, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.214536666870117, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.3673548996448517, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9400880932807922, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4120640754699707, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.05974338576197624, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7115685343742371, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.321321964263916, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5516669750213623, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.609588384628296, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7361023426055908, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.7284692525863647, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7159745097160339, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4855232238769531, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3746167421340942, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9901514649391174, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8227580189704895, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2183674573898315, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.820101261138916, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3905342817306519, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.522040843963623, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6593911647796631, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8610382676124573, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8440227508544922, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4669026136398315, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2232524156570435, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9730647802352905, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.4397852420806885, Batch Acc is 0.703125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2922227382659912, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.4672882556915283, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0326907634735107, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8880194425582886, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.3818763792514801, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6542149186134338, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.8198388814926147, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7384607195854187, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2804867029190063, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6962460875511169, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.9344032406806946, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0897883176803589, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6569784879684448, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3586455583572388, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3026105165481567, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.666130006313324, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.7346482872962952, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.6153108477592468, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.3756400346755981, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.472879558801651, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.0022166967391968, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.722144365310669, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.084322690963745, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5617797374725342, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4907253384590149, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.4333927631378174, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.8028637170791626, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 2.711655378341675, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.868931233882904, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5708858966827393, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 0.5150842666625977, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 1 Train Loss: 1.2556400299072266, Batch Acc is 0.640625\n",
            "\n",
            "[Val Epoch]: 1 , Accuracy: 0.8448988795280457, Valid Loss: 1.6269290447235107\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9833435416221619, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.268514633178711, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2270209789276123, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8717268109321594, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.8415638208389282, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.695621132850647, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.3445253372192383, Batch Acc is 0.671875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.144555687904358, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5837303400039673, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8154559135437012, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.168045163154602, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.13004636764526367, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9578186869621277, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7545660734176636, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1810866594314575, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7675328254699707, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2113033533096313, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6923747062683105, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0721631050109863, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3994122743606567, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7741095423698425, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.583341360092163, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9548646211624146, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.4745686948299408, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7518569827079773, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.011963367462158, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3909584283828735, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9442874789237976, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3539738655090332, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8746237754821777, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7985244989395142, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.566173791885376, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.9785823822021484, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2520357370376587, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9389352798461914, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7274004220962524, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3436657190322876, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.4230850040912628, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5572712421417236, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0461910963058472, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4161890745162964, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4434691667556763, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.033449172973633, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6936832666397095, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8575406670570374, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9715741276741028, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1744487285614014, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.023522973060608, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0351948738098145, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.180009126663208, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.8709734678268433, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1398708820343018, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1459400653839111, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.2103543281555176, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7943047285079956, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.36073431372642517, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5271035432815552, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1721667051315308, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.9188296794891357, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0234036445617676, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9155815839767456, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.9608714580535889, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1959450244903564, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9138462543487549, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.723122000694275, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0845483541488647, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.2643384635448456, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.708305835723877, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8862435817718506, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6826859712600708, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9071462750434875, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4975827932357788, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.32211440801620483, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.928720235824585, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.188938856124878, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5998684167861938, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1023696660995483, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.049060821533203, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4206950664520264, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 3.2886674404144287, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.0113120079040527, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.083409309387207, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8598108291625977, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5095587968826294, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.3957870900630951, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6719650030136108, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3554093837738037, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1141260862350464, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.693579912185669, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.25456318259239197, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.66488116979599, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3806638717651367, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.753807008266449, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9307346940040588, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2139734029769897, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6544702649116516, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.764380693435669, Batch Acc is 0.6875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1034823656082153, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2162946462631226, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8474566340446472, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.40474608540534973, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5772497653961182, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8453698754310608, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8747459650039673, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3164323568344116, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8867622017860413, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8599765300750732, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7963240146636963, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7704980969429016, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9384487867355347, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4905112981796265, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4071710109710693, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.8551191091537476, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7951720952987671, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0175904035568237, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7907901406288147, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3614206314086914, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6921093463897705, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.42954811453819275, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.597464680671692, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0508159399032593, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5395147800445557, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8696210384368896, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6178909540176392, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9930675029754639, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0373692512512207, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0534929037094116, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.106848120689392, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0720149278640747, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.657540500164032, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2871469259262085, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9302058815956116, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.695252537727356, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3771904706954956, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.171546459197998, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.402894377708435, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6619080305099487, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0522326231002808, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9870275855064392, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.40135669708251953, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7875711917877197, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7151446342468262, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.493157982826233, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8764538168907166, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9767419099807739, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1039221286773682, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.3043112754821777, Batch Acc is 0.6875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3102772235870361, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.34447285532951355, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1842981576919556, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.15798020362854, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6457701325416565, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9296574592590332, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2681657075881958, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.850431203842163, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.802518367767334, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9160557985305786, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.8426094055175781, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3841456174850464, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.753182590007782, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.35390931367874146, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.454882264137268, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0338287353515625, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.2130942344665527, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6908917427062988, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.472777009010315, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0974125862121582, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4100252389907837, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.66953706741333, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3800718784332275, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.2226452827453613, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9535050392150879, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1487632989883423, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.225931167602539, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1590124368667603, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2704883813858032, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6803582906723022, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3786221742630005, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.6665518283843994, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.3837496042251587, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5618370175361633, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8487681150436401, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.9788439273834229, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7194068431854248, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.401784062385559, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2924315929412842, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7709444761276245, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5566678643226624, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6014129519462585, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9483917951583862, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7213994264602661, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.201998233795166, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.412153720855713, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.3119751811027527, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7683359384536743, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.753722608089447, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1231967210769653, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0617412328720093, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7870262265205383, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9185287952423096, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3820915222167969, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.242815613746643, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7261651754379272, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5467606782913208, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8411892652511597, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5932040214538574, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3237441778182983, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.3910110890865326, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0046889781951904, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2355380058288574, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6047030091285706, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4970757961273193, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.4121660888195038, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6839207410812378, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.2345201075077057, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1168009042739868, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0890202522277832, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.044191598892212, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5457605123519897, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1805118322372437, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.019886016845703, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4035184383392334, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7011116147041321, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9492262005805969, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9393287897109985, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6902137398719788, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8406013250350952, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6815226078033447, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7860976457595825, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.8869385719299316, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3041273355484009, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.1308836936950684, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0587584972381592, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4938347339630127, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4976896047592163, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.4496781826019287, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.141633987426758, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.0674922466278076, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3750501871109009, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0434608459472656, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2266048192977905, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6367335319519043, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4384585618972778, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2569758892059326, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1634844541549683, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8881537914276123, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5282602310180664, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1645275354385376, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0558611154556274, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2877123355865479, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0599150657653809, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4908897876739502, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.9702101945877075, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.599663257598877, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9692381024360657, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.3098198175430298, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2965675592422485, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5788220167160034, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.62351393699646, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0395333766937256, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9773250818252563, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7561967372894287, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3682152032852173, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5533874034881592, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5071035623550415, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5810177326202393, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0118917226791382, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3700844049453735, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6548473834991455, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5404118299484253, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8678574562072754, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.9749674797058105, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5611549019813538, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2529432773590088, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.709776759147644, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9787763357162476, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4478037357330322, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6970654726028442, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.001408576965332, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8006342649459839, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7021325826644897, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8861935138702393, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.817578911781311, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1074907779693604, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7909705638885498, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9347037076950073, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.8934898376464844, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3511905670166016, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.115936517715454, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0427589416503906, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.958897352218628, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5710042119026184, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5730416178703308, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7485610246658325, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7728250026702881, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.067017674446106, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6927388906478882, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7179090976715088, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0408024787902832, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5127097368240356, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8939935564994812, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.335189938545227, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6747209429740906, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8464186787605286, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6425975561141968, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.354248285293579, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.3759573996067047, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4252901077270508, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5831322073936462, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.075803518295288, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6181960105895996, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2787598371505737, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2179443836212158, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5782716870307922, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.756794273853302, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3774968385696411, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6487793922424316, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.215070903301239, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9508642554283142, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0079917907714844, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.36777132749557495, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.2367919683456421, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3459937572479248, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8729180693626404, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.1627793312072754, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9524129033088684, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8822479844093323, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2983993291854858, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7600637674331665, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0728205442428589, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0717040300369263, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0652772188186646, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.65322345495224, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7167757749557495, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7655308246612549, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7177584171295166, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.2883909940719604, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6299273371696472, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.961537778377533, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.37753531336784363, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8786996603012085, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6726692318916321, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.8582496643066406, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 2.1162805557250977, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0578192472457886, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7329834699630737, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7377917170524597, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7086989283561707, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.472692608833313, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6908314228057861, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.484140545129776, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.320794701576233, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.714066982269287, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6717653274536133, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9574128985404968, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9346352815628052, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.297355055809021, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5761171579360962, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7554603815078735, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.27877116203308105, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.515582799911499, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.189510464668274, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.9464769959449768, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.020180106163025, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.3852163553237915, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6516137719154358, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.5699647665023804, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.6988365650177002, Batch Acc is 0.71875\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.7428953051567078, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.26774263381958, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0990787744522095, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.282666802406311, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.890846848487854, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.7234001159667969, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.348373144865036, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.5426379442214966, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.269263505935669, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.6470896601676941, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.0159718990325928, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8080456256866455, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 1.4542584419250488, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 2 Train Loss: 0.8050025701522827, Batch Acc is 0.640625\n",
            "\n",
            "[Val Epoch]: 2 , Accuracy: 0.8527113795280457, Valid Loss: 0.2749652564525604\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.1544586420059204, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.7624117136001587, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3474611043930054, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.7508553266525269, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.0039006471633911, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.33079442381858826, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.2724066972732544, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.5427494049072266, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3190191984176636, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9554921388626099, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.6002354025840759, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.2734832167625427, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8317424654960632, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.6240353584289551, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8558244109153748, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.0330631732940674, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9165369868278503, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.0984835624694824, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9060218930244446, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.6854093074798584, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3395127058029175, Batch Acc is 0.765625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.555987536907196, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8487747311592102, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.5205192565917969, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.1887550801038742, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.30967724323272705, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.2839381694793701, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.931084394454956, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.790343999862671, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9869763851165771, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.571955144405365, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.118765950202942, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8907018303871155, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.0162044763565063, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.6827326416969299, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 2.398787021636963, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.0330268144607544, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.5859099626541138, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.5595534443855286, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.2822332382202148, Batch Acc is 0.734375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.661554753780365, Batch Acc is 0.921875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.4150993824005127, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.4507245421409607, Batch Acc is 0.953125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3397495746612549, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 2.43300199508667, Batch Acc is 0.75\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 2.2828099727630615, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9213637709617615, Batch Acc is 0.90625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.805420458316803, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8349995017051697, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 2.5600154399871826, Batch Acc is 0.78125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.1828709840774536, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9194539785385132, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.5544428825378418, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3390824794769287, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.7868779897689819, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9452471733093262, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8176169991493225, Batch Acc is 0.875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.6198630332946777, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.0940852165222168, Batch Acc is 0.8125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.4686516523361206, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.1966869831085205, Batch Acc is 0.890625\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8976805806159973, Batch Acc is 0.9375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3483322858810425, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3106294870376587, Batch Acc is 0.796875\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.778603732585907, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.9717591404914856, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.3591482639312744, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 1.1046000719070435, Batch Acc is 0.828125\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8983303308486938, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.8353079557418823, Batch Acc is 0.84375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.611487090587616, Batch Acc is 0.859375\n",
            "\n",
            "[Train Epoch]: 3 Train Loss: 0.7098630666732788, Batch Acc is 0.875\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Driving train test loop\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)):\n\u001b[0;32m----> 3\u001b[0m     train_step(train_loader, epoch)\n\u001b[1;32m      4\u001b[0m     val_step(val_loader, epoch)\n\u001b[1;32m      5\u001b[0m     \u001b[39m#scheduler.step()\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[17], line 8\u001b[0m, in \u001b[0;36mtrain_step\u001b[0;34m(loader, epoch)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39m# model.encoder.eval()\u001b[39;00m\n\u001b[1;32m      6\u001b[0m total_epoch_loss\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfor\u001b[39;00m batch_id, (video_data,labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loader):\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m     \u001b[39m# video_data,labels = video_data.to(device), labels.to(device)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     video_data,labels \u001b[39m=\u001b[39m video_data\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/utils/data/dataset.py:298\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(idx, \u001b[39mlist\u001b[39m):\n\u001b[1;32m    297\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindices[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m idx]]\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
            "Cell \u001b[0;32mIn[5], line 72\u001b[0m, in \u001b[0;36mUCFDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     70\u001b[0m imgs \u001b[39m=\u001b[39m []\n\u001b[1;32m     71\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m idxs:\n\u001b[0;32m---> 72\u001b[0m     frame \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(vid[k]\u001b[39m.\u001b[39masnumpy())\n\u001b[1;32m     73\u001b[0m     frame \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform(frame)\n\u001b[1;32m     74\u001b[0m     imgs\u001b[39m.\u001b[39mappend(frame)\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/decord/video_reader.py:104\u001b[0m, in \u001b[0;36mVideoReader.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mif\u001b[39;00m idx \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_frame \u001b[39mor\u001b[39;00m idx \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    103\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m out of bound: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(idx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_frame))\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseek_accurate(idx)\n\u001b[1;32m    105\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext()\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/decord/video_reader.py:232\u001b[0m, in \u001b[0;36mVideoReader.seek_accurate\u001b[0;34m(self, pos)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    231\u001b[0m \u001b[39massert\u001b[39;00m pos \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m pos \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_frame\n\u001b[0;32m--> 232\u001b[0m success \u001b[39m=\u001b[39m _CAPI_VideoReaderSeekAccurate(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle, pos)\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m success:\n\u001b[1;32m    234\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFailed to seek_accurate to frame \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(pos))\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/decord/_ffi/_ctypes/function.py:173\u001b[0m, in \u001b[0;36mFunctionBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    171\u001b[0m ret_val \u001b[39m=\u001b[39m DECORDValue()\n\u001b[1;32m    172\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[0;32m--> 173\u001b[0m check_call(_LIB\u001b[39m.\u001b[39;49mDECORDFuncCall(\n\u001b[1;32m    174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle, values, tcodes, ctypes\u001b[39m.\u001b[39;49mc_int(num_args),\n\u001b[1;32m    175\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(ret_val), ctypes\u001b[39m.\u001b[39;49mbyref(ret_tcode)))\n\u001b[1;32m    176\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    177\u001b[0m _ \u001b[39m=\u001b[39m args\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Driving train test loop\n",
        "for epoch in tqdm(range(1,epochs+1)):\n",
        "    train_step(train_loader, epoch)\n",
        "    val_step(val_loader, epoch)\n",
        "    #scheduler.step()\n",
        "    torch.save(model,\"dino_model.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddef979a",
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Expected state_dict to be dict-like, got <class '__main__.MLP'>.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m MLP(\u001b[39m384\u001b[39m,\u001b[39m512\u001b[39m,\u001b[39m101\u001b[39m,dinov2_vits14)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39mdino_model.pt\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[1;32m      3\u001b[0m model\u001b[39m.\u001b[39mto(device)\n",
            "File \u001b[0;32m~/miniconda3/envs/dinov2/lib/python3.9/site-packages/torch/nn/modules/module.py:1994\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[39m\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Copies parameters and buffers from :attr:`state_dict` into\u001b[39;00m\n\u001b[1;32m   1972\u001b[0m \u001b[39mthis module and its descendants. If :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[1;32m   1973\u001b[0m \u001b[39mthe keys of :attr:`state_dict` must exactly match the keys returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[39m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   1992\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 1994\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mExpected state_dict to be dict-like, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mtype\u001b[39m(state_dict)))\n\u001b[1;32m   1996\u001b[0m missing_keys: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1997\u001b[0m unexpected_keys: List[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m []\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class '__main__.MLP'>."
          ]
        }
      ],
      "source": [
        "model = MLP(384,512,101,dinov2_vits14)\n",
        "model.load_state_dict(torch.load('dino_model.pth'))\n",
        "model.to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "r4ptG3LVMKXX",
      "metadata": {
        "id": "r4ptG3LVMKXX"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "GHHJtUrmkjb1",
      "metadata": {
        "id": "GHHJtUrmkjb1"
      },
      "outputs": [],
      "source": [
        "# test the trained model  \n",
        "def test_model(loader):\n",
        "\n",
        "    model.eval()\n",
        "    corrects=0\n",
        "    total_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_id, (input_data,labels) in enumerate(loader):\n",
        "            \n",
        "            input_data = input_data.to(device)\n",
        "            \n",
        "            labels = labels.to(device)\n",
        "            prediction = model(input_data)\n",
        "            loss = loss_criterion(prediction,labels)\n",
        "            total_loss += loss.item()\n",
        "            corrects+= (torch.argmax(prediction,dim=1)==labels).sum()\n",
        "    \n",
        "    accuracy = corrects/(len(loader)*test_batch_size)\n",
        "    print(f\"Test Accuracy: {accuracy}, Test Loss: {total_loss}\")\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "proprietary-shell",
      "metadata": {
        "id": "proprietary-shell"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.8407205939292908, Test Loss: 11977.843482483195\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "tensor(0.8407, device='cuda:0')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "test_model(test_loader)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "BAsvl78-MO_D",
      "metadata": {
        "id": "BAsvl78-MO_D"
      },
      "source": [
        "## Visualize results on tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "increasing-delaware",
      "metadata": {
        "id": "increasing-delaware"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cqqvXqp4G2uI",
      "metadata": {
        "id": "cqqvXqp4G2uI"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ViViT_UCF101.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
